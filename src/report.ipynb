{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "iml-term-project",
   "display_name": "Python 3.8.6 64-bit ('iml-term-project-VNmOTpJK': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Ville Kopio, Kaggle username: vkopio\n",
    "\n",
    "# Introduction \n",
    "\n",
    "In this project the task was to predict whether the news source is a reputable media or an opinionated source by only seeing the headline of an article. The training data was composed of headlines from Reuters being classified as reputable and headlines from opinionated sources that were deemed false by PolitiFact. Two different preprocessing techniques were used on the headlines and multiple machine learning models were trained with the preprocessed headlines to see if the classification was possible within reasonable accuracy. \n",
    "\n",
    "# Results \n",
    "\n",
    "As the task was a binary classification task, the accuracy of the models should not be below $0.5$ as we might as well just randomly guess the outcome and achieve, on average, better results. Throughout the model training process, a three-fold cross-validation was used to estimate the model accuracy by taking the mean of the validation scores. Many different algorithms were trained with the data set but ultimately logistic regression, SVM and gradient boosting were chosen for the official results. The implementation of XGBoost was done by a third-party library that did not work too well with `sklearn`. Source code for the different models can still be found from the [project repository](https://github.com/vkopio/aml-project). \n",
    "\n",
    "## Algorithms trained with BOW \n",
    "\n",
    "**Logistic regression** is a special case of generalized linear model which models a Bernoulli distribution with a sigmoid function taken from a linear combination of the sample features. The algorithm tries to do maximum likelihood estimation by minimizing the negative log-likelihood loss function. This can be done in many ways, for example by stochastic gradient descent or iteratively reweighted least squares. The algorithm used in this project instead used SAGA solver which optimizes a sum of convex functions which should be faster than traditional SGD. L2 regularization was also used. The trained model can predict the class of new data points and gives a probability of it belonging to either class. A threshold of 0.5 probability is used to determine if the data point is classified to class 0 or class 1. The trained model gained a mean cross-validation accuracy of $0.770$ and test accuracy of $0.776$. \n",
    "\n",
    "A **support vector machine** tries to maximize the margin between (in this case) two classes by minimizing the length of the norm of the margin. To handle misclassification and margin violations, it assigns slack variables greater than one to misclassified samples, less than one to samples inside the margins and zero to correctly classified samples. The sum of the slack variables is added to the minimization problem and the sum is multiplied by the regularization parameter $C$ which was set to one. The SVM model in this project also uses radial basis function (RBF) kernel to make it possible to have a nonlinear model. The model had test accuracy of $0.789$. \n",
    "\n",
    "**Gradient boosting**, like any boosting algorithm, combines multiple weak learners to make a final decision based on how each of the weak learner \"voted\" to classify the data. It is quite similar with Adaboost as it is regarded as a generalized version of it. Instead of giving larger weights to samples that were misclassified previously or, in other words, minimizing a specialized loss function, it can use many different loss functions. Gradient boosting can also use many different weak learners (just like Adaboost) and criterion for a single split along with many hyperparameters. While testing different parameters, exponential loss gave best results which technically makes the algorithm Adaboost. Decision trees were used as the weak learners with a maximum tree depth of 3 and the split criterion used was MSE. The model had test accuracy of $0.783$. \n",
    "\n",
    "## Algorithms trained with LDA \n",
    "\n",
    "There seems to be an upper limit with the BOW representation of the headlines for accuracy at around $0.78$. To get around of this issue, another approach with the preprocessing would be needed in order to have better results. The chosen method was *latent dirichlet allocation* (LDA) which uses matrix decomposition to extract topics from the headlines and assigns a weight per topic for each headline. [MALLET](http://mallet.cs.umass.edu/) was used to do the topic extraction as it gave the best results for the data set. The number of topics was set to $25$ as it gave the best coherence score of $0.36$ for the data set. The coherence score still is relatively low as scores bellow $0.6$ are regarded as poor results so better performance can probably be possible with different NLP methods. \n",
    "\n",
    "Using the LDA data set to train the models significantly better test accuracies were achieved. **Logistic regression** had test accuracy of $0.865$ and **SVM** had $0.866$ with no significant impact changing the regularization parameter. With the default hyper parameters, the **gradient boosting** model already gave comparable results with SVM so they were fine-tuned further using grid search cross-validation. The resulting model gave a test accuracy of $0.887$. \n",
    "\n",
    "| Model | BOW test accuracy | LDA test accuracy | \n",
    "| ----- | ----------------: | ----------------: | \n",
    "| Logistic regression | 0.776 | 0.865 | \n",
    "| SVM | 0.789 | 0.866 | \n",
    "| Gradient boosting | 0.783 | 0.887 | \n",
    "\n",
    "# Conclusions \n",
    "\n",
    "It can be seen from the results that the data preprocessing methods have a significant impact on performance in NLP classification problems. Only by changing the preprocessing method from BOW to LDA, albeit being quite a bit more sophisticated, the logistic regression model's mean cross-validation accuracy went from $0.77$ to $0.86$. With a gradient boosting model, the accuracy was pushed to $0.887$. As the LDA topic extraction gave quite a bad cohesion with very similar topics the training data was not very optimal. With minor changes to the used words, it could be quite easy to trick the classifier. Furthermore, there might be a bias towards \"well written\" headlines as Reuters has professionals writing and crafting good headlines where as \"opinionated sources\" will not necessarily possess such craftmanship. Therefore, writing headlines in \"professional\" manner could make it more likely to pass the classification as reputable. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}